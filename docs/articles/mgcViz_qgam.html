<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title> • mgcViz</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">mgcViz</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/mgcViz_qgam.html">UNKNOWN TITLE</a>
    </li>
    <li>
      <a href="../articles/mgcviz.html">mgcViz: visual tools for GAMs</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1></h1>
            
          </div>

    
    
<div class="contents">
<!--
%\VignetteEngine{knitr::docco_linear}
%\VignetteIndexEntry{qgam_vignette}
-->
<div id="quantile-additive-models-using-qgam-and-mgcviz" class="section level1">
<h1 class="hasAnchor">
<a href="#quantile-additive-models-using-qgam-and-mgcviz" class="anchor"></a>Quantile additive models using <strong>qgam</strong> and <strong>mgcViz</strong>
</h1>
<p>The <code>qgam</code> R package offers methods for fitting additive quantile regression models based on splines, using the methods described in <a href="https://arxiv.org/abs/1707.03307">Fasiolo et al., 2017</a>. It is useful to use <code>qgam</code> together with <code>mgcViz</code>, which extends the basic visualizations provided by <code>mgcv</code>.</p>
<p>The main fitting functions are:</p>
<ul>
<li>
<code>qgam()</code> fits an additive quantile regression model to a single quantile. Very similar to <code><a href="http://www.rdocumentation.org/packages/mgcv/topics/gam">mgcv::gam()</a></code>. It returns an object of class <code>qgam</code>, which inherits from <code><a href="http://www.rdocumentation.org/packages/mgcv/topics/gamObject">mgcv::gamObject</a></code>.</li>
<li>
<code>mqgam()</code> fits the same additive quantile regression model to several quantiles. It is more efficient that calling <code>qgam()</code> several times, especially in terms of memory usage.</li>
<li>
<code><a href="../reference/qgamV.html">qgamV()</a></code> and <code><a href="../reference/mqgamV.html">mqgamV()</a></code> are two convenient wrappers that fit quantile GAMs and return <code>gamViz</code> objects, for which <code>mgcViz</code> provides lots of visualizations.</li>
</ul>
</div>
<div id="basic-example-income-vs-age" class="section level1">
<h1 class="hasAnchor">
<a href="#basic-example-income-vs-age" class="anchor"></a>Basic example: income vs age</h1>
<p>We load the data and fit a median model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mgcViz)
<span class="kw">library</span>(SemiPar)
<span class="kw">data</span>(age.income)
age.income$income &lt;-<span class="st"> </span><span class="kw">exp</span>(age.income$log.income)

fitQ &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(income ~<span class="st"> </span>age, <span class="dt">data =</span> age.income, <span class="dt">qu =</span> <span class="fl">0.5</span>)   </code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5........done</code></pre>
<p>We predict and plot</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ft &lt;-<span class="st">  </span><span class="kw">predict</span>(fitQ, <span class="dt">se =</span> <span class="ot">TRUE</span>)

ord &lt;-<span class="st"> </span><span class="kw">order</span>(age.income$age)
<span class="kw">plot</span>(age.income$age, age.income$income, <span class="dt">xlab =</span> <span class="st">"Age"</span>, 
     <span class="dt">ylab =</span> <span class="st">"Income (CAD)"</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)
<span class="kw">lines</span>(age.income$age[ord], ft$fit[ord] , <span class="dt">col =</span> <span class="dv">1</span>) 
<span class="kw">lines</span>(age.income$age[ord], (ft$fit +<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>ft$se.fit)[ord], <span class="dt">col =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(age.income$age[ord], (ft$fit -<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>ft$se.fit)[ord], <span class="dt">col =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/age2-1.png" width="672" style="display:block; margin: auto"></p>
<p>We can look at p-values etc:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fitQ)</code></pre></div>
<pre><code>## 
## Family: elf 
## Link function: identity 
## 
## Formula:
## income ~ age
## 
## Parametric coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   440368     100598   4.378  1.2e-05 ***
## age            10157       2697   3.766 0.000166 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## 
## R-sq.(adj) =  0.0791   Deviance explained = 5.53%
## -REML = 2926.1  Scale est. = 1         n = 205</code></pre>
<p>The relation between median <code>income</code> and <code>age</code> is clearly non-linear:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitQ &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(income ~<span class="st"> </span><span class="kw">s</span>(age), <span class="dt">data =</span> age.income, <span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5.........done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ft &lt;-<span class="st">  </span><span class="kw">predict</span>(fitQ, <span class="dt">se =</span> <span class="ot">TRUE</span>)

<span class="kw">plot</span>(age.income$age, age.income$income, <span class="dt">xlab =</span> <span class="st">"Age"</span>, 
     <span class="dt">ylab =</span> <span class="st">"Income (CAD)"</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)
<span class="kw">lines</span>(age.income$age[ord], ft$fit[ord], <span class="dt">col =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(age.income$age[ord], (ft$fit +<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>ft$se.fit)[ord], <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(age.income$age[ord], (ft$fit -<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>ft$se.fit)[ord], <span class="dt">col =</span> <span class="dv">2</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/age4-1.png" width="672" style="display:block; margin: auto"></p>
<p>Now we fit multiple quantile at once, then we predict and plot the fit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitQ &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mqgamV.html">mqgamV</a></span>(income ~<span class="st"> </span><span class="kw">s</span>(age), <span class="dt">data =</span> age.income, <span class="dt">qu =</span> <span class="kw">c</span>(<span class="fl">0.1</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.9</span>))</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5.........done 
## qu = 0.25........done 
## qu = 0.75...........done 
## qu = 0.1.........done 
## qu = 0.9.....................done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(age.income$age, age.income$income, <span class="dt">xlab =</span> <span class="st">"Age"</span>, <span class="dt">ylab =</span> <span class="st">"Income (CAD)"</span>, <span class="dt">col =</span> <span class="st">"grey"</span>)

for(ii in <span class="dv">1</span>:<span class="dv">5</span>){
  ft &lt;-<span class="st">  </span><span class="kw">predict</span>(fitQ[[ii]], <span class="dt">se =</span> <span class="ot">TRUE</span>)
  <span class="kw">lines</span>(age.income$age[ord], ft$fit[ord], <span class="dt">col =</span> <span class="dv">1</span>)
}</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/age5-1.png" width="672" style="display:block; margin: auto"></p>
<p>Notice that the fitting quantiles <strong>will</strong> cross somewhere:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newd &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">age =</span> <span class="kw">seq</span>(<span class="dv">22</span>, <span class="dv">80</span>, <span class="dt">length.out =</span> <span class="fl">1e3</span>))
<span class="kw">plot</span>(age.income$age, age.income$income, <span class="dt">xlab =</span> <span class="st">"Age"</span>, 
     <span class="dt">ylab =</span> <span class="st">"Income (CAD)"</span>, <span class="dt">col =</span> <span class="st">"grey"</span>, <span class="dt">xlim =</span> <span class="kw">range</span>(newd$age))
for(ii in <span class="dv">1</span>:<span class="dv">5</span>){
  ft &lt;-<span class="st">  </span><span class="kw">predict</span>(fitQ[[ii]], <span class="dt">newdata =</span> newd, <span class="dt">se =</span> <span class="ot">TRUE</span>)
  <span class="kw">lines</span>(newd$age, ft$fit, <span class="dt">col =</span> <span class="dv">1</span>)
  <span class="kw">rug</span>(age.income$age)
}</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/age6-1.png" width="672" style="display:block; margin: auto"> Typically they cross far from the data (when you extrapolate), but they can also cross when you intrapolate.</p>
<p>The output of <code>mqgamV</code> is a list of QGAM models, you can handle each of them as usual:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fitQ[[<span class="dv">1</span>]])</code></pre></div>
<pre><code>## 
## Family: elf 
## Link function: identity 
## 
## Formula:
## income ~ s(age)
## 
## Parametric coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   430445      28337   15.19   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##          edf Ref.df Chi.sq  p-value    
## s(age) 4.964  5.997  68.32 9.09e-13 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.116   Deviance explained = 71.9%
## -REML = 2943.4  Scale est. = 1         n = 205</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fitQ[[<span class="dv">1</span>]])</code></pre></div>
<pre><code>## 
## Family: elf 
## Link function: identity 
## 
## Formula:
## income ~ s(age)
## 
## Parametric coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   430445      28337   15.19   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##          edf Ref.df Chi.sq  p-value    
## s(age) 4.964  5.997  68.32 9.09e-13 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.116   Deviance explained = 71.9%
## -REML = 2943.4  Scale est. = 1         n = 205</code></pre>
</div>
<div id="an-additive-example-with-four-covariates" class="section level1">
<h1 class="hasAnchor">
<a href="#an-additive-example-with-four-covariates" class="anchor"></a>An additive example with four covariates</h1>
<p>We simulate some data from the model: <span class="math display">\[
y \sim f_0(x_0)+f_1(x_1)+f_2(x_2)+f_3(x_3)+e,\;\;\; e \sim N(0, 2)
\]</span> by doing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2</span>)
dat &lt;-<span class="st"> </span><span class="kw">gamSim</span>(<span class="dv">1</span>, <span class="dt">n=</span><span class="dv">1000</span>, <span class="dt">dist=</span><span class="st">"normal"</span>, <span class="dt">scale=</span><span class="dv">2</span>)[<span class="kw">c</span>(<span class="st">"y"</span>, <span class="st">"x0"</span>, <span class="st">"x1"</span>, <span class="st">"x2"</span>, <span class="st">"x3"</span>)]</code></pre></div>
<pre><code>## Gu &amp; Wahba 4 term additive model</code></pre>
<p>We start by fitting a linear quantile model for the median:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(y ~<span class="st"> </span>x0 +<span class="st"> </span>x1 +<span class="st"> </span>x2 +<span class="st"> </span>x3, <span class="dt">data=</span>dat, <span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5.........done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit1, <span class="dt">allTerms =</span> <span class="ot">TRUE</span>), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD2-1.png" width="672" style="display:block; margin: auto"> We use <code>pages = 1</code> to plot on a single page, and <code>allTerms</code> to plot also the parametric effects (the plotting method used here plots only smooth or random effects by default).</p>
<p>Should we use a smooth effect of <code>x0</code>? If the effect of <code>x0</code> was non-linear, we would expect that the number of observations falling below the fit would depart from 0.5, as we move along <code>x0</code>. A rudimental diagnostic plot is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(dat$x0, <span class="kw">sign</span>(<span class="kw">residuals</span>(fit1)) +<span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(dat), <span class="dv">0</span>, <span class="fl">0.05</span>), <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="dv">1</span>, <span class="fl">0.4</span>), <span class="dt">pch =</span> <span class="dv">16</span>, 
     <span class="dt">ylab =</span> <span class="st">"Residuals sign"</span>, <span class="dt">xlab =</span> <span class="st">"x0"</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD3a-1.png" width="672" style="display:block; margin: auto"> But residual pattern is more visible in the following plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/check1D.html">check1D</a></span>(fit1, <span class="st">"x0"</span>) +<span class="st"> </span><span class="kw"><a href="../reference/l_gridQCheck1D.html">l_gridQCheck1D</a></span>(<span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD3-1.png" width="672" style="display:block; margin: auto"> There is definitely a pattern here. An analogous plot along <code>x2</code> also shows a residual pattern, hence we consider the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(y ~<span class="st"> </span><span class="kw">s</span>(x0) +<span class="st"> </span>x1 +<span class="st"> </span><span class="kw">s</span>(x2) +<span class="st"> </span>x3, <span class="dt">data=</span>dat, <span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5.........done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/check1D.html">check1D</a></span>(fit2, <span class="st">"x0"</span>) +<span class="st"> </span><span class="kw"><a href="../reference/l_gridQCheck1D.html">l_gridQCheck1D</a></span>(<span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD4-1.png" width="672" style="display:block; margin: auto"> Looks much better, and leads to much lower AIC:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(fit1) -<span class="st"> </span><span class="kw">AIC</span>(fit2)</code></pre></div>
<pre><code>## [1] 693.1062</code></pre>
<p>We can plot all the smooth effects by doing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit2), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD5-1.png" width="672" style="display:block; margin: auto"> To print only the second we do</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit2, <span class="dt">select =</span> <span class="dv">2</span>), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD6-1.png" width="672" style="display:block; margin: auto"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit2, <span class="dt">allTerms =</span> <span class="ot">TRUE</span>), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD7-1.png" width="672" style="display:block; margin: auto"> Now we fit this model to multiple quantiles and plot the fitted effects:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mqgamV.html">mqgamV</a></span>(y ~<span class="st"> </span><span class="kw">s</span>(x0) +<span class="st"> </span>x1 +<span class="st"> </span><span class="kw">s</span>(x2) +<span class="st"> </span>x3, <span class="dt">data=</span>dat, 
              <span class="dt">qu =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dt">length.out =</span> <span class="dv">5</span>))</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5.........done 
## qu = 0.3........done 
## qu = 0.7........done 
## qu = 0.1........done 
## qu = 0.9.........done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit, <span class="dt">allTerms =</span> <span class="ot">TRUE</span>), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD8-1.png" width="672" style="display:block; margin: auto"></p>
<p>We can manipulate the five fitted quantile GAMs individually, for example</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit[[<span class="dv">1</span>]], <span class="dt">allTerms =</span> <span class="ot">TRUE</span>), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/fourD9-1.png" width="672" style="display:block; margin: auto"></p>
</div>
<div id="random-effect-modelling-lexical-decision-task" class="section level1">
<h1 class="hasAnchor">
<a href="#random-effect-modelling-lexical-decision-task" class="anchor"></a>Random effect modelling: lexical decision task</h1>
<p>In this experiment participants are presented with a sequence of stimuli and they have to decide, as quickly as possible, whether each stimulus is an existing words (eg. house) or a non-existing word (eg. pensour) by pressing one of two buttons. The variables we consider here are:</p>
<ul>
<li>
<code>RT</code> logarithmically transformed reaction time.</li>
<li>
<code>NativeLanguage</code> a factor with levels English and Other.</li>
<li>
<code>Length</code> the word’s length in letters.</li>
<li>
<code>Frequency</code> logarithmically transformed lemma frequencies as available in the CELEX lexical database.</li>
<li>
<code>Subject</code> the id of the individual subjects.</li>
<li>
<code>Trial</code> the rank of the trial in the experimental list.</li>
<li>
<code>Word</code> a factor with 79 words as levels.</li>
</ul>
<p>We might be interested in modeling the relation between the response time and length, frequency, native language and trial, and we might want to control for word and subject. We start by loading the data and fitting a simple QGAM model for the median:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(languageR)
<span class="kw">data</span>(lexdec)

lexdec$RT0 &lt;-<span class="st"> </span><span class="kw">exp</span>( lexdec$RT ) <span class="co"># Should not need to use log-responses to normalize</span>

fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(RT0 ~<span class="st"> </span><span class="kw">s</span>(Trial) +<span class="st"> </span>NativeLanguage +<span class="st"> </span><span class="kw">s</span>(Length, <span class="dt">k =</span> <span class="dv">5</span>) +<span class="st"> </span><span class="kw">s</span>(Frequency),
            <span class="dt">data =</span> lexdec, <span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5...........done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex1-1.png" width="672" style="display:block; margin: auto"> It is natural to ask ourselves whether we should control for <code>Subject</code> and for <code>Word</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># check1D(fit, "Subject") would not work because it was not included in the original fit</span>
<span class="kw"><a href="../reference/check1D.html">check1D</a></span>(fit, lexdec$Subject) +<span class="st"> </span><span class="kw"><a href="../reference/l_gridQCheck1D.html">l_gridQCheck1D</a></span>(<span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex2-1.png" width="672" style="display:block; margin: auto"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/check1D.html">check1D</a></span>(fit, lexdec$Word) +<span class="st"> </span><span class="kw"><a href="../reference/l_gridQCheck1D.html">l_gridQCheck1D</a></span>(<span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex2-2.png" width="672" style="display:block; margin: auto"> It seems so, hence we refit using two random effects:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(RT0 ~<span class="st"> </span><span class="kw">s</span>(Trial) +<span class="st"> </span>NativeLanguage +<span class="st"> </span><span class="kw">s</span>(Length, <span class="dt">k =</span> <span class="dv">5</span>) +
<span class="st">                    </span><span class="kw">s</span>(Frequency) +<span class="st"> </span><span class="kw">s</span>(Subject, <span class="dt">bs =</span> <span class="st">"re"</span>) +<span class="st"> </span><span class="kw">s</span>(Word, <span class="dt">bs =</span> <span class="st">"re"</span>),
            <span class="dt">data =</span> lexdec, <span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5................done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/check1D.html">check1D</a></span>(fit2, <span class="st">"Subject"</span>) +<span class="st"> </span><span class="kw"><a href="../reference/l_gridQCheck1D.html">l_gridQCheck1D</a></span>(<span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex3-1.png" width="672" style="display:block; margin: auto"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/check1D.html">check1D</a></span>(fit2, <span class="st">"Word"</span>) +<span class="st"> </span><span class="kw"><a href="../reference/l_gridQCheck1D.html">l_gridQCheck1D</a></span>(<span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex3-2.png" width="672" style="display:block; margin: auto"></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(fit) -<span class="st"> </span><span class="kw">AIC</span>(fit2)</code></pre></div>
<pre><code>## [1] 831.9406</code></pre>
<p>We achieve lower AIC and the residuals checks look better (especially the one for <code>Subject</code>).</p>
<p>A potentially interesting question is then: is the effect of <code>Trial</code> different for native and non-native speakers? We can verify this by using a by-factor smooth:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/qgamV.html">qgamV</a></span>(RT0 ~<span class="st">  </span><span class="kw">s</span>(Trial, <span class="dt">by =</span> NativeLanguage) +<span class="st"> </span><span class="co"># &lt;- by-factor smooth</span>
<span class="st">                    </span>NativeLanguage +<span class="st"> </span><span class="kw">s</span>(Length, <span class="dt">k =</span> <span class="dv">5</span>) +<span class="st"> </span><span class="kw">s</span>(Frequency) +<span class="st"> </span>
<span class="st">                    </span><span class="kw">s</span>(Subject, <span class="dt">bs =</span> <span class="st">"re"</span>) +<span class="st"> </span><span class="kw">s</span>(Word, <span class="dt">bs =</span> <span class="st">"re"</span>),
             <span class="dt">data =</span> lexdec, <span class="dt">qu =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5................done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit3), <span class="dt">pages =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex4-1.png" width="672" style="display:block; margin: auto"> Can look directly at the difference between the by-factor smooths by doing:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">s1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sm.html">sm</a></span>(fit3, <span class="dv">1</span>)
s2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/sm.html">sm</a></span>(fit3, <span class="dv">2</span>)
<span class="kw"><a href="../reference/plotDiff.html">plotDiff</a></span>(s1, s2) +<span class="st"> </span><span class="kw"><a href="../reference/l_ciPoly.html">l_ciPoly</a></span>() +<span class="st"> </span><span class="kw"><a href="../reference/l_fitLine.html">l_fitLine</a></span>()</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex5-1.png" width="672" style="display:block; margin: auto"> There might be something there, but the difference is not very strong.</p>
<p>Now that we have converges on a (hopefully reasonable) model, we can fit it to several quantiles:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit5 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mqgamV.html">mqgamV</a></span>(RT0 ~<span class="st"> </span><span class="kw">s</span>(Trial, <span class="dt">by =</span> NativeLanguage) +<span class="st"> </span>NativeLanguage +<span class="st"> </span><span class="kw">s</span>(Length, <span class="dt">k =</span> <span class="dv">5</span>) +
<span class="st">                </span>+<span class="st"> </span><span class="kw">s</span>(Frequency) +<span class="st"> </span><span class="kw">s</span>(Subject, <span class="dt">bs =</span> <span class="st">"re"</span>) +<span class="st"> </span><span class="kw">s</span>(Word, <span class="dt">bs =</span> <span class="st">"re"</span>),
                <span class="dt">data =</span> lexdec, <span class="dt">qu =</span> <span class="kw">seq</span>(<span class="fl">0.2</span>, <span class="fl">0.8</span>, <span class="dt">length.out =</span> <span class="dv">5</span>))</code></pre></div>
<pre><code>## Estimating learning rate. Each dot corresponds to a loss evaluation. 
## qu = 0.5................done 
## qu = 0.35..............done 
## qu = 0.65...........done 
## qu = 0.2...................done 
## qu = 0.8...........done</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">plot</span>(fit5, <span class="dt">allTerms =</span> <span class="ot">TRUE</span>), <span class="dt">pages =</span> <span class="dv">2</span>, <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="mgcViz_qgam_files/figure-html/lex6-1.png" width="672" style="display:block; margin: auto"><img src="mgcViz_qgam_files/figure-html/lex6-2.png" width="672" style="display:block; margin: auto"> The effects are fairly stable across quantiles, the effect of <code>Frequency</code> might be stronger for high quantiles. We can examine the fitted quantile models individually:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fit5[[<span class="dv">5</span>]])</code></pre></div>
<pre><code>## 
## Family: elf 
## Link function: identity 
## 
## Formula:
## RT0 ~ s(Trial, by = NativeLanguage) + NativeLanguage + s(Length, 
##     k = 5) + +s(Frequency) + s(Subject, bs = "re") + s(Word, 
##     bs = "re")
## 
## Parametric coefficients:
##                     Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)           628.06      31.71   19.80   &lt;2e-16 ***
## NativeLanguageOther   121.46      48.01    2.53   0.0114 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Approximate significance of smooth terms:
##                                   edf Ref.df  Chi.sq  p-value    
## s(Trial):NativeLanguageEnglish  2.209  2.733   8.549   0.0247 *  
## s(Trial):NativeLanguageOther    1.196  1.356   1.084   0.5103    
## s(Length)                       1.003  1.004   0.760   0.3842    
## s(Frequency)                    2.789  3.062  36.605 7.26e-08 ***
## s(Subject)                     18.483 19.000 887.093  &lt; 2e-16 ***
## s(Word)                        43.908 76.000 207.518 3.21e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## R-sq.(adj) =  0.438   Deviance explained = 46.8%
## -REML =  10834  Scale est. = 1         n = 1659</code></pre>
<!-- Adaptive smoothing: the motorcycle dataset -->
<!-- ======================= -->
<!-- Let's start with a simple example. Here we are fitting a regression model with an adaptive spline basis to quantile 0.8 of the motorcycle dataset. -->
<!-- ```{r 1, message = F} -->
<!-- library(qgam); library(MASS) -->
<!-- if( suppressWarnings(require(RhpcBLASctl)) ){ blas_set_num_threads(1) } # Optional -->
<!-- set.seed(6436) -->
<!-- fit <- qgam(accel~s(times, k=20, bs="ad"),  -->
<!--             data = mcycle,  -->
<!--             qu = 0.8,  -->
<!--             err = 0.1, -->
<!--             control = list("tol" = 0.01)) # <- sloppy tolerance to speed-up calibration  -->
<!-- # Plot the fit -->
<!-- xSeq <- data.frame(cbind("accel" = rep(0, 1e3), "times" = seq(2, 58, length.out = 1e3))) -->
<!-- pred <- predict(fit, newdata = xSeq, se=TRUE) -->
<!-- plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", ylim = c(-150, 80)) -->
<!-- lines(xSeq$times, pred$fit, lwd = 1) -->
<!-- lines(xSeq$times, pred$fit + 2*pred$se.fit, lwd = 1, col = 2) -->
<!-- lines(xSeq$times, pred$fit - 2*pred$se.fit, lwd = 1, col = 2)    -->
<!-- ``` -->
<!-- `qgam` automatically calls `tuneLearnFast` to select the learning rate. The results of the calibrations are stored in `fit$calibr`. We can check whether the optimization succeded as follows: -->
<!-- ```{r 2} -->
<!-- check(fit$calibr, 2) -->
<!-- ``` -->
<!-- The plot suggest that the calibration criterion has a single minimum, and that the optimizer has converged to its neighbourhood. Alternatively, we could have selected the learning rate by evaluating the loss function on a grid. -->
<!-- ```{r 3, message = F} -->
<!-- set.seed(6436) -->
<!-- cal <- tuneLearn(accel~s(times, k=20, bs="ad"),  -->
<!--                  data = mcycle,  -->
<!--                  qu = 0.8, -->
<!--                  err = 0.1, -->
<!--                  lsig = seq(1, 3, length.out = 20),  -->
<!--                  control = list("progress" = "none")) #<- sequence of values for learning rate -->
<!-- check(cal) -->
<!-- ``` -->
<!-- Here the generic `check` function produces a different output. The first plot is the calibration criterion as a function of $log(\sigma)$, which should look fairly smooth. The second plot shows how the effective degrees of freedom (EDF) vary with $log(\sigma)$. Notice that here we are using an adaptive smoother, which includes five smoothing parameters.  -->
<!-- We might want to fit several quantiles at once. This can be done with `mqgam`. -->
<!-- ```{r 4} -->
<!-- quSeq <- c(0.2, 0.4, 0.6, 0.8) -->
<!-- set.seed(6436) -->
<!-- fit <- mqgam(accel~s(times, k=20, bs="ad"),  -->
<!--              data = mcycle,  -->
<!--              err = 0.1, -->
<!--              qu = quSeq,  -->
<!--              control = list("tol" = 0.01)) # <- sloppy tolerance to speed-up calibration  -->
<!-- ``` -->
<!-- To save memory `mqgam` does not return one `mgcv::gamObject` for each quantile, but it avoids storing some redundant data (such as several copies of the design matrix). The output of `mqgam` can be manipulated using the `qdo` function. -->
<!-- ```{r 5} -->
<!-- # Plot the data -->
<!-- xSeq <- data.frame(cbind("accel" = rep(0, 1e3), "times" = seq(2, 58, length.out = 1e3))) -->
<!-- plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", ylim = c(-150, 80)) -->
<!-- # Predict each quantile curve and plot -->
<!-- for(iq in quSeq){ -->
<!--   pred <- qdo(fit, iq, predict, newdata = xSeq) -->
<!--   lines(xSeq$times, pred, col = 2) -->
<!-- } -->
<!-- ``` -->
<!-- Using `qdo` we can print out the summary for each quantile, for instance:  -->
<!-- ```{r 6} -->
<!-- # Summary for quantile 0.4 -->
<!-- qdo(fit, qu = 0.4, summary) -->
<!-- ``` -->
<!-- Notice that here the generic function `summary` is calling `summary.gam`, because `summary.qgam` has not been implemented yet. Hence one cannot quite rely on the p-value provided by this function, because their are calculated using result that apply to parametric, not quantile, regression. -->
<!-- Dealing with heteroscedasticity -->
<!-- ======================= -->
<!-- Let us simulate some data from an heteroscedastic model. -->
<!-- ```{r h1} -->
<!-- set.seed(651) -->
<!-- n <- 5000 -->
<!-- x <- seq(-4, 3, length.out = n) -->
<!-- X <- cbind(1, x, x^2) -->
<!-- beta <- c(0, 1, 1) -->
<!-- sigma =  1.2 + sin(2*x) -->
<!-- f <- drop(X %*% beta) -->
<!-- dat <- f + rnorm(n, 0, sigma) -->
<!-- dataf <- data.frame(cbind(dat, x)) -->
<!-- names(dataf) <- c("y", "x") -->
<!-- qus <- seq(0.05, 0.95, length.out = 10) -->
<!-- plot(x, dat, col = "grey", ylab = "y") -->
<!-- for(iq in qus){ lines(x, qnorm(iq, f, sigma)) } -->
<!-- ``` -->
<!-- We now fit ten quantiles between 0.05 and 0.95, using a quantile GAM with scalar learning rate. To speed up things I've pre-computed the learning rate. Just comment out the line `lsig = lsig,` if you want to re-computed it. -->
<!-- ```{r h2} -->
<!-- lsig <- c(-0.96, -0.83, -0.69, -0.63, -0.76, -0.76, -0.89, -0.85, -0.99, -1.06) -->
<!-- fit <- mqgam(y~s(x, k = 30, bs = "cr"),  -->
<!--              data = dataf, -->
<!--              lsig = lsig, -->
<!--              qu = qus, err = 0.05) -->
<!-- qus <- seq(0.05, 0.95, length.out = 10) -->
<!-- plot(x, dat, col = "grey", ylab = "y") -->
<!-- for(iq in qus){  -->
<!--  lines(x, qnorm(iq, f, sigma), col = 2) -->
<!--  lines(x, qdo(fit, iq, predict)) -->
<!-- } -->
<!-- legend("top", c("truth", "fitted"), col = 2:1, lty = rep(1, 2)) -->
<!-- ``` -->
<!-- The fitted quantiles are close to the true ones, but their credible intervals don't vary much with x. Indeed, let's look at intervals for quantile 0.95. -->
<!-- ```{r h3} -->
<!-- plot(x, dat, col = "grey", ylab = "y") -->
<!-- tmp <- qdo(fit, 0.95, predict, se = TRUE) -->
<!-- lines(x, tmp$fit) -->
<!-- lines(x, tmp$fit + 3 * tmp$se.fit, col = 2) -->
<!-- lines(x, tmp$fit - 3 * tmp$se.fit, col = 2) -->
<!-- ``` -->
<!-- We can do better by letting the learning rate vary with the covariate. In particular, we can use an additive model for quantile location and one for the scale or learning rate. Here I am fixing the intercept of  -->
<!-- the additive model for the learning rate, in order to avoid calibrating it. Just comment out `lsig=-1.16` if -->
<!-- you want to re-estimate it. -->
<!-- ```{r h4} -->
<!-- fit <- qgam(list(y~s(x, k = 30, bs = "cr"), ~ s(x, k = 30, bs = "cr")),  -->
<!--             data = dataf, qu = 0.95, err = 0.05, lsig = -1.16) -->
<!-- plot(x, dat, col = "grey", ylab = "y") -->
<!-- tmp <- predict(fit, se = TRUE) -->
<!-- lines(x, tmp$fit[ , 1]) -->
<!-- lines(x, tmp$fit[ , 1] + 3 * tmp$se.fit[ , 1], col = 2) -->
<!-- lines(x, tmp$fit[ , 1] - 3 * tmp$se.fit[ , 1], col = 2) -->
<!-- ``` -->
<!-- Now the credible intervals correctly represent the underlying uncertainty.  -->
<!-- Model checking -->
<!-- ======================= -->
<!-- The `qgam` package provides some functions that can be useful for model checking. In particular, we have: -->
<!--    - `cqcheck` if we are fitting, say, quantile 0.2 we expect roughly $20\%$ of the observations to fall below the fitted quantile. This function produces some plots to verify this. -->
<!--    - `cqcheckI` interactive version of `cqcheckI`. Implemented using the `shiny` package. Not demonstrated here,  -->
<!--                 but see `?cqcheckI`. -->
<!--    - `check.qgam` provides some diagnostics regarding the optimization. Mainly based to `gam.check`. -->
<!--    - `check.learn` diagnostic checks to verify that the learning rate selection went well. It can be used -->
<!--                    on the output of `tuneLearn`. -->
<!--    - `check.tuneLearn` similar to `check.learn`, but it can be used on the output of `tuneLearn` or on the                              `$calibr` slot of a `qgam` object. -->
<!-- We start by illustrating the `cqcheck` function. In particular, let us consider the additive model: -->
<!-- $$ -->
<!-- y \sim x+x^2+z+xz/2+e,\;\;\; e \sim N(0, 1) -->
<!-- $$ -->
<!-- We start by simulating some data from it. -->
<!-- ```{r c1} -->
<!-- library(qgam) -->
<!-- set.seed(15560) -->
<!-- n <- 1000 -->
<!-- x <- rnorm(n, 0, 1); z <- rnorm(n) -->
<!-- X <- cbind(1, x, x^2, z, x*z) -->
<!-- beta <- c(0, 1, 1, 1, 0.5) -->
<!-- y <- drop(X %*% beta) + rnorm(n)  -->
<!-- dataf <- data.frame(cbind(y, x, z)) -->
<!-- names(dataf) <- c("y", "x", "z") -->
<!-- ``` -->
<!-- We fit a linear model to the median and we use `cqcheck` produce a diagnostic plot.  -->
<!-- ```{r c2} -->
<!-- qu <- 0.5 -->
<!-- fit <- qgam(y~x, qu = qu, data = dataf) -->
<!-- cqcheck(obj = fit, v = c("x"), X = dataf, y = y)  -->
<!-- ``` -->
<!-- The `cqcheck` function takes a `qgam` object as input and it predicts the conditional quantile using the data in `X`. Then it bins the responses `y` using the corresponding values of `v` and it calculates, for every bin, what fraction of responses falls below the fitted quantile. Given that we are fitting the median, we would expect that around $50\%$ of the point falls below the fit. But, as the plot shows, this fraction varies widely along `x`. There is clearly a non-linear relation between the quantile location and `x`, hence we add a smooth for `x`. -->
<!-- ```{r c3, message = F} -->
<!-- fit <- qgam(y~s(x), qu = qu, data = dataf) -->
<!-- cqcheck(obj = fit, v = c("x"), X = dataf, y = y) -->
<!-- ``` -->
<!-- The deviations from the theoretical quantile ($0.5$) are much reduced, but let's look across both `x` and `z`.  -->
<!-- ```{r c4, message = F} -->
<!-- cqcheck(obj = fit, v = c("x", "z"), X = dataf, y = y, nbin = c(5, 5)) -->
<!-- ``` -->
<!-- This plot uses binning as before, if a bin is red (green) this means that the fraction of responses falling below the fit is smaller (larger) than 0.5. Bright colours means that the deviation is statistically significant. As we move along `z` (`x2` in the plot) the colour changes from green to red, so it make sense drawing a marginal plot for `z`: -->
<!-- ```{r c5, message = F} -->
<!-- cqcheck(obj = fit, v = c("z"), X = dataf, y = y, nbin = c(10)) -->
<!-- ``` -->
<!-- We are clearly missing an effect here. Given that effect looks pretty linear, we simply add a parametric term to the fit, which seems to solve the problem: -->
<!-- ```{r c6, message = F} -->
<!-- fit <- qgam(y~s(x)+z, qu = qu, data = dataf) -->
<!-- cqcheck(obj = fit, v = c("z")) -->
<!-- ``` -->
<!-- But if we look again across both `x` and `z` we see that green prevails on the top-left to bottom-right -->
<!-- diagonal, while the other diagonal is mainly red. -->
<!-- ```{r c7, message = F} -->
<!-- cqcheck(obj = fit, v = c("x", "z"), nbin = c(5, 5)) -->
<!-- ``` -->
<!-- This suggests that adding an interaction between `x` and `z` might be a good idea. Indeed, now `cqcheck` does not signal any problem: -->
<!-- ```{r c8, message = F} -->
<!-- fit <- qgam(y~s(x)+z+I(x*z), qu = qu, data = dataf) -->
<!-- cqcheck(obj = fit, v = c("x", "z"), nbin = c(5, 5)) -->
<!-- ``` -->
<!-- Now that we are fairly satisfied with the model structure, we can, for instance, fit several quantiles -->
<!-- by doing:  -->
<!-- ```{r c9, message = F} -->
<!-- fit <- mqgam(y~s(x)+z+I(x*z), qu = c(0.2, 0.4, 0.6, 0.8), data = dataf) -->
<!-- ``` -->
<!-- We can then check whether the learning rate was selected correctly. Recall that the `qgam` function calls internally `tuneLearnFast`, hence we can look at how the calibration went by doing: -->
<!-- ```{r c10, message = F} -->
<!-- check.learnFast(fit$calibr, 2:5) -->
<!-- ``` -->
<!-- For each quantile, the calibration loss seems to have a unique minimum, which is what one would hope. Objects of class `qgam` can also be checked using the generic function `check`, which defaults to `check.qgam`. To use this function on the output of `mqgam`, we must use the `qdo` function: -->
<!-- ```{r c11, message = F} -->
<!-- qdo(fit, 0.2, check) -->
<!-- ``` -->
<!-- The printed output gives some information about the optimizer used to estimate the smoothing parameters, for fixed learning rate. See `?check.qgam` for more information. The plot has been obtained using `cqcheck`, where each data point has been binned using the fitted values. On the right side of the plot there seems to be some large deviations, but the rug shows that there are very few data points there.   -->
<!-- Application to probabilistic electricity load forecasting -->
<!-- ======================= -->
<!-- Here we consider a UK electricity demand dataset, taken from the national grid [website](http://www2.nationalgrid.com/). The dataset covers the period January 2011 to June 2016 and it contains the following variables: -->
<!--    - `NetDemand` net electricity demand between 11:30am and 12am. -->
<!--    - `wM` instantaneous temperature, averaged over several English cities. -->
<!--    - `wM_s95` exponential smooth of `wM`, that is `wM_s95[i] = a*wM[i] + (1-a)*wM_s95[i]` with `a=0.95`. -->
<!--    - `Posan` periodic index in `[0, 1]` indicating the position along the year. -->
<!--    - `Dow` factor variable indicating the day of the week. -->
<!--    - `Trend` progressive counter, useful for defining the long term trend. -->
<!--    - `NetDemand.48` lagged version of `NetDemand`, that is `NetDemand.48[i] = NetDemand[i-2]`. -->
<!--    - `Holy` binary variable indicating holidays. -->
<!--    - `Year` and `Date` should obvious, and partially redundant. -->
<!-- See [Fasiolo et al., 2016](https://arxiv.org/abs/1707.03307) for more details. This is how the demand over the period looks like: -->
<!-- ```{r edf1} -->
<!-- data("UKload") -->
<!-- tmpx <- seq(UKload$Year[1], tail(UKload$Year, 1), length.out = nrow(UKload))  -->
<!-- plot(tmpx, UKload$NetDemand, type = 'l', xlab = 'Year', ylab = 'Load') -->
<!-- ``` -->
<!-- To estimate the median demand, we consider the following model -->
<!-- ```{r edf2} -->
<!-- qu <- 0.5 -->
<!-- form <- NetDemand~s(wM,k=20,bs='cr') + s(wM_s95,k=20,bs='cr') +  -->
<!--         s(Posan,bs='ad',k=30,xt=list("bs"="cc")) + Dow + s(Trend,k=4) + NetDemand.48 + Holy -->
<!-- ``` -->
<!-- Notice that we use very few knots for the long term trend, this is because we don't want to end up interpolating the data. We use an adaptive cyclic smooth for `Posan`, we'll explain later why adaptivity is needed here.  -->
<!-- Now we tune the learning rate on a grid, on two cores. As the first plot shows, the calibrations loss is minimized at $\log (\sigma)\approx 6$, the second plot shows how the effective degrees of freedom of each smooth term changes with $\log (\sigma)$. -->
<!-- ```{r edf3, message=FALSE} -->
<!-- set.seed(41241) -->
<!-- sigSeq <- seq(4, 8, length.out = 16) -->
<!-- closs <- tuneLearn(form = form, data = UKload,  -->
<!--                    lsig = sigSeq, qu = qu, control = list("K" = 20),  -->
<!--                    multicore = TRUE, ncores = 2, err = 0.1) -->
<!-- check(closs) -->
<!-- ``` -->
<!-- Now let's fit the model with the learning rate corresponding to the lowest loss and let's look at the resulting smooth effects.  -->
<!-- ```{r edf4} -->
<!-- lsig <- closs$lsig -->
<!-- fit <- qgam(form = form, data = UKload, lsig = lsig, qu = qu, err = 0.1) -->
<!-- plot(fit, scale = F, page = 1) -->
<!-- ``` -->
<!-- The effect of temperature (`wM`) is minimized around 18 degrees, which is reasonable. The cyclic effect of `Posan` has a very sharp drop corresponding to the winter holidays, we used an adaptive smooth in order to have more flexibility during this period. Now we can have a look as some diagnostic plot: -->
<!-- ```{r edf5} -->
<!-- par(mfrow = c(2, 2)) -->
<!-- cqcheck(fit, v = c("wM"), main = "wM") -->
<!-- cqcheck(fit, v = c("wM_s95"), main = "wM_s95") -->
<!-- cqcheck(fit, v = c("Posan"), main = "Posan") -->
<!-- cqcheck(fit, v = c("Trend"), main = "Trend", xaxt='n') -->
<!-- axis(1, at = UKload$Trend[c(1, 500, 1000, 1500, 2000)],  -->
<!--              UKload$Year[c(1, 500, 1000, 1500, 2000)] ) -->
<!-- ``` -->
<!-- The plots for `wM_s95` and `Posan` don't show any important deviation from 0.5, the target quantile. Along `wM` we see a large deviation, but we have essentially no data for very high temperatures. If we look at deviations along the `Trend` variable, which is just a time counter, we see several important deviations. It would be interesting verifying why these occur (we have no answer currently). -->
<!-- Finally, recall that we can produce 2D versions of these diagnostic plots, for instance: -->
<!-- ```{r edf6} -->
<!-- par(mfrow = c(1, 1)) -->
<!-- cqcheck(fit, v = c("wM", "Posan"), scatter = T) -->
<!-- ``` -->
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<ul>
<li>Fasiolo, M., Goude, Y., Nedellec, R. and Wood, S. N. (2017). Fast calibrated additive quantile regression. Available at <a href="https://arxiv.org/abs/1707.03307" class="uri">https://arxiv.org/abs/1707.03307</a>
</li>
</ul>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#quantile-additive-models-using-qgam-and-mgcviz">Quantile additive models using <strong>qgam</strong> and <strong>mgcViz</strong></a></li>
      <li><a href="#basic-example-income-vs-age">Basic example: income vs age</a></li>
      <li><a href="#an-additive-example-with-four-covariates">An additive example with four covariates</a></li>
      <li><a href="#random-effect-modelling-lexical-decision-task">Random effect modelling: lexical decision task</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Matteo Fasiolo, Raphael Nedellec.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
